import math
import os
from typing import Tuple
import pickle
from models.discriminator import MinibatchDiscriminator, DGWGAN
from models.generator import Generator

from models.generator import *

import torch
import torchvision
import torchvision.transforms.functional as F
import dnnlib

device = 'cuda' if torch.cuda.is_available() else 'cpu'

def adjust_gen_images(imgs: torch.tensor,
                      bounds: Tuple[torch.tensor, torch.tensor], size: int):
    """
    Change the value range of images generated by StyleGAN2. Outputs are usually roughly in the range [-1, 1]. 
    A linear transformation is then applied following the transformation used in the official implementation to save images.
    Images are resized to a given size using bilinear interpolation.
    """
    lower_bound, upper_bound = bounds
    lower_bound = lower_bound.float().to(imgs.device)
    upper_bound = upper_bound.float().to(imgs.device)
    imgs = torch.where(imgs > upper_bound, upper_bound, imgs)
    imgs = torch.where(imgs < lower_bound, lower_bound, imgs)
    imgs = F.center_crop(imgs, (700, 700))
    imgs = F.resize(imgs, size)
    return imgs


def save_images(imgs: torch.tensor, folder, filename, center_crop=800):
    """Save StyleGAN output images in file(s).

    Args:
        imgs (torch.tensor): generated images in [-1, 1] range
        folder (str): output folder
        filename (str): name of the files
    """
    imgs = imgs.detach()
    if center_crop:
        imgs = F.center_crop(imgs, (center_crop, center_crop))
    imgs = (imgs * 0.5 + 128 / 255).clamp(0, 1)
    for i, img in enumerate(imgs):
        path = os.path.join(folder, f'{filename}_{i}.png')
        torchvision.utils.save_image(img, path)


def create_image(w,
                 generator,
                 crop_size=None,
                 resize=None,
                 batch_size=20,
                 device='cuda:0'):
    with torch.no_grad():
        if w.shape[1] == 1:
            w_expanded = torch.repeat_interleave(w,
                                                 repeats=generator.num_ws,
                                                 dim=1)
        else:
            w_expanded = w

        w_expanded = w_expanded.to(device)
        imgs = []
        for i in range(math.ceil(w_expanded.shape[0] / batch_size)):
            w_batch = w_expanded[i * batch_size:(i + 1) * batch_size]
            imgs_generated = generator(w_batch,
                                                 noise_mode='const',
                                                 force_fp32=True)
            imgs.append(imgs_generated.cpu())

        imgs = torch.cat(imgs, dim=0)
        if crop_size is not None:
            imgs = F.center_crop(imgs, (crop_size, crop_size))
        if resize is not None:
            imgs = F.resize(imgs, resize)
        return imgs


def get_DCGAN(dataset, gan_type, gan_model_dir, n_classes, z_dim, target_model):
    G = Generator(z_dim)
    if gan_type == True:
        D = MinibatchDiscriminator(n_classes=n_classes)
    else:
        D = DGWGAN(3)

    if gan_type == True:
        path = os.path.join(os.path.join(gan_model_dir, dataset), target_model)
        path_G = os.path.join(path, "improved_{}_G.tar".format(dataset))
        path_D = os.path.join(path, "improved_{}_D.tar".format(dataset))
    else:
        path = os.path.join(gan_model_dir, dataset)
        path_G = os.path.join(path, "{}_G.tar".format(dataset))
        path_D = os.path.join(path, "{}_D.tar".format(dataset))

    print(f"G path: {path_G}")
    print(f"D path: {path_D}")

    G = torch.nn.DataParallel(G).to(device)
    D = torch.nn.DataParallel(D).to(device)
    ckp_G = torch.load(path_G)
    G.load_state_dict(ckp_G['state_dict'], strict=True)
    ckp_D = torch.load(path_D)
    D.load_state_dict(ckp_D['state_dict'], strict=True)

    G.eval()
    D.eval()
    
    return G, D

def get_CGAN(dataset, gen_num_features, gen_bottom_width, distribution, gan_model_dir, n_classes, z_dim, target_model):
    G = ResNetGenerator(
        num_features=gen_num_features, dim_z=z_dim, bottom_width=gen_bottom_width,
        num_classes=n_classes, distribution=distribution
    )

    path = os.path.join(gan_model_dir, dataset)
    path_G = os.path.join(path, "{}_G.tar".format(target_model))

    print(f"G path: {path_G}")

    gen_ckpt = torch.load(path_G)['model']
    G.load_state_dict(gen_ckpt, strict=True)
    
    G = torch.nn.DataParallel(G).to(device)
    G.eval()
    
    return G

def get_stylegan(prior, stylegan_model_dir):
    stylegan_path = os.path.join(os.path.join(stylegan_model_dir, prior), "network-snapshot-025000.pkl")
    # stylegan_path = os.path.join(os.path.join(stylegan_model_dir, prior), "network-snapshot-003687-fid7.66.pkl")

    print('Loading networks from "%s"...' % stylegan_path)

    with dnnlib.util.open_url(stylegan_path) as f:
        data = pickle.load(f)
        G = data['G_ema'].to(device)  # type: ignore
        D = data['D'].to(device)

    G.eval()
    D.eval()
    
    return G, D